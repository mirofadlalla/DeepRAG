'''
Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ

ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ chunk Ø¥Ù„Ù‰ vector:

normalized
reusable
cached
deterministic

Ø¨Ø­ÙŠØ«:

âŒ Ù…ÙÙŠØ´ chunk ÙŠØªØ¹Ù…Ù„Ù‡ embedding Ù…Ø±ØªÙŠÙ†
âŒ Ù…ÙÙŠØ´ drift
âœ… Ø£ÙŠ Ø¥Ø¹Ø§Ø¯Ø© ingestion ØªØ¨Ù‚Ù‰ cheap

Ø§Ù„Ù…Ø´ÙƒÙ„Ø©

Ù„Ùˆ Ø¹Ù†Ø¯Ùƒ:
100k chunks

ÙƒÙ„ Ù…Ø±Ø© ØªØ´ØºÙ„ Ø§Ù„Ø³ÙŠØ³ØªÙ… Ø¨ØªØ¹Ù…Ù„ embedding Ù…Ù† Ø§Ù„Ø£ÙˆÙ„

ÙŠØ¨Ù‚Ù‰:
cost - latency - waste


âœ… Ø§Ù„Ø­Ù„

Ù†Ø¹Ù…Ù„ Embedding Cache Layer
ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰:

ðŸ”‘ Key => hash(chunk_text)


Ù„ÙŠÙ‡ Ù…Ø´ chunk_idØŸ
chunk_id ÙÙŠÙ‡ metadata

embedding Ù„Ø§Ø²Ù… ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ ÙÙ‚Ø·
'''
import os
import hashlib
from typing import List, Dict
import logging

import pickle
from zenml import step
import numpy as np
from sentence_transformers import SentenceTransformer

# Ø¥Ø¹Ø¯Ø§Ø¯ logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

class EmbeddingCache:
    def __init__(self, cache_dir: str = "data/processed/embeddings"):
        self.cache_dir = cache_dir
        os.makedirs(self.cache_dir, exist_ok=True)

    def _path(self, text_hash: str) -> str:
        '''
        Get the file path for a given text hash
    '''
        return os.path.join(self.cache_dir, f"{text_hash}.npy")

    def exists(self, text_hash: str) -> bool:
        '''
        Check if embedding for the given text hash exists in cache
        '''
        return os.path.exists(self._path(text_hash))

    def load(self, text_hash: str) -> np.ndarray:
        '''
        Load the embedding for the given text hash from cache
        '''
        return np.load(self._path(text_hash))

    def save(self, text_hash: str, vector: np.ndarray):
        '''
        Save the embedding for the given text hash to cache
        '''
        np.save(self._path(text_hash), vector)


class Embedder:
    def __init__(self, model_name="BAAI/bge-m3", device="cuda", batch_size=32):
        '''
        model_name: name of the sentence transformer model
        device: "cuda" or "cpu"
        batch_size: number of texts to encode in a single batch
        '''
        self.model = SentenceTransformer(model_name, device=device)
        self.batch_size = batch_size
        self.cache = EmbeddingCache()

    def _hash(self, text: str) -> str:
        return hashlib.sha256(text.encode("utf-8")).hexdigest()

    def chunk_embeded(self, chunks):
        '''
        Chunks: List of dicts with keys 'id', 'text', 'metadata
        Returns: List of dicts with keys 'chunk_id', 'vector', 'metadata'
        '''
        embedded = []
        texts_to_encode = []
        chunk_indices = []

        for i, chunk in enumerate(chunks):
            text = chunk["text"]
            text_hash = self._hash(text)
            if self.cache.exists(text_hash):
                vector = self.cache.load(text_hash)
                embedded.append({
                    "chunk_id": chunk["id"],
                    # "text" : chunk["text"],
                    "vector": vector,
                    "metadata": chunk["metadata"]
                })
            else:
                texts_to_encode.append(text)
                chunk_indices.append(i)
                embedded.append(None)  # placeholder

        if texts_to_encode:
            logging.info(f"Encoding {len(texts_to_encode)} chunks in batches of {self.batch_size}...")
            vectors = self.model.encode(texts_to_encode, batch_size=self.batch_size, normalize_embeddings=True)
            for idx, vector in zip(chunk_indices, vectors):
                chunk = chunks[idx]
                text_hash = self._hash(chunk["text"])
                self.cache.save(text_hash, vector)
                embedded[idx] = {
                    "chunk_id": chunk["id"],
                    # "text" : chunk["text"],
                    "vector": vector,
                    "metadata": chunk["metadata"]
                }

        logging.info("All chunks embedded âœ…")

        return embedded
        # output_path = r"E:\pyDS\Buliding Rag System\embedded_chunks.pkl"

        # print("Saving embedded chunks...")
        # with open(output_path, "wb") as f:
        #     pickle.dump(embedded, f)

        # print("Saved successfully at:", output_path)


@step(enable_cache=True)
def chunks_embedding(chunks) :
    em = Embedder()
    return em.chunk_embeded(chunks)
